#!/usr/bin/env python3
"""bdd — Behavior-Driven Development catalog manager.

Manages a catalog.json of goals, expectations, and facets.
Used by humans, Curation Claude, and Implementation Claude.
"""

import argparse
import json
import os
import sys

CATALOG_FILE = "catalog.json"

def find_catalog():
    """Find catalog.json in current directory or parents."""
    d = os.getcwd()
    while True:
        path = os.path.join(d, CATALOG_FILE)
        if os.path.exists(path):
            return path
        parent = os.path.dirname(d)
        if parent == d:
            return os.path.join(os.getcwd(), CATALOG_FILE)
        d = parent

def load_catalog(path=None):
    path = path or find_catalog()
    if not os.path.exists(path):
        print(f"Error: No {CATALOG_FILE} found. Run 'bdd init' first.", file=sys.stderr)
        sys.exit(1)
    with open(path) as f:
        return json.load(f), path

def save_catalog(catalog, path):
    with open(path, "w") as f:
        json.dump(catalog, f, indent=2)
        f.write("\n")

def next_id(nodes, prefix):
    max_n = 0
    for n in nodes:
        if n["id"].startswith(prefix + "-"):
            try:
                num = int(n["id"].split("-", 1)[1])
                if num > max_n:
                    max_n = num
            except ValueError:
                pass
    return f"{prefix}-{max_n + 1:03d}"

TYPE_PREFIX = {"goal": "g", "expectation": "e", "facet": "f"}

def get_node(nodes, node_id):
    for n in nodes:
        if n["id"] == node_id:
            return n
    return None

def get_children(nodes, parent_id):
    return [n for n in nodes if n.get("parent") == parent_id]

def get_ancestor_chain(nodes, node_id):
    """Return list from root to node."""
    chain = []
    current = get_node(nodes, node_id)
    while current:
        chain.append(current)
        pid = current.get("parent")
        current = get_node(nodes, pid) if pid else None
    chain.reverse()
    return chain

def compute_status(nodes, node):
    """Compute status for any node from descendant facets."""
    if node["type"] == "facet":
        return node.get("status", "untested")
    children = get_children(nodes, node["id"])
    if not children:
        return "untested"
    statuses = [compute_status(nodes, c) for c in children]
    if all(s == "passing" for s in statuses):
        return "passing"
    if any(s == "failing" for s in statuses):
        return "failing"
    return "untested"

def status_icon(status):
    if status == "passing":
        return "[+]"
    if status == "failing":
        return "[-]"
    return "[ ]"

# --- Commands ---

def cmd_init(args):
    path = os.path.join(os.getcwd(), CATALOG_FILE)
    if os.path.exists(path) and not args.force:
        print(f"{CATALOG_FILE} already exists. Use --force to overwrite.", file=sys.stderr)
        sys.exit(1)
    catalog = {"version": 1, "nodes": []}
    save_catalog(catalog, path)
    print(f"Created {path}")

def cmd_status(args):
    catalog, _ = load_catalog()
    nodes = catalog["nodes"]
    goals = [n for n in nodes if n["type"] == "goal"]
    expectations = [n for n in nodes if n["type"] == "expectation"]
    facets = [n for n in nodes if n["type"] == "facet"]
    passing = [f for f in facets if f.get("status") == "passing"]
    failing = [f for f in facets if f.get("status") == "failing"]
    untested = [f for f in facets if f.get("status", "untested") == "untested"]

    total = len(facets)
    coverage = (len(passing) / total * 100) if total > 0 else 0

    satisfied = sum(1 for e in expectations if compute_status(nodes, e) == "passing")
    unsatisfied = len(expectations) - satisfied

    if args.json:
        print(json.dumps({
            "goals": len(goals),
            "expectations": len(expectations),
            "facets": total,
            "passing": len(passing),
            "failing": len(failing),
            "untested": len(untested),
            "coverage": round(coverage, 1),
            "satisfied": satisfied,
            "unsatisfied": unsatisfied,
        }))
    else:
        print(f"Goals:        {len(goals)}")
        print(f"Expectations: {len(expectations)} ({satisfied} satisfied, {unsatisfied} unsatisfied)")
        print(f"Facets:       {total}")
        print(f"  Passing:    {len(passing)}")
        print(f"  Failing:    {len(failing)}")
        print(f"  Untested:   {len(untested)}")
        print(f"Coverage:     {coverage:.0f}%")

def cmd_next(args):
    catalog, _ = load_catalog()
    nodes = catalog["nodes"]
    expectations = [n for n in nodes if n["type"] == "expectation"]

    # Sort by priority (lower = higher priority), filter unsatisfied
    unsatisfied = [e for e in expectations if compute_status(nodes, e) != "passing"]
    unsatisfied.sort(key=lambda e: e.get("priority", 99))

    if not unsatisfied:
        if args.json:
            print(json.dumps(None))
        else:
            print("All expectations satisfied!")
        return

    exp = unsatisfied[0]
    facets = get_children(nodes, exp["id"])
    parent = get_node(nodes, exp.get("parent"))

    if args.json:
        print(json.dumps({
            "expectation": exp,
            "facets": facets,
            "parent_goal": parent,
        }))
    else:
        if parent:
            print(f"Goal: {parent['id']} — {parent['text']}")
            print()
        print(f"Expectation: {exp['id']} — {exp['text']}")
        if exp.get("priority"):
            print(f"Priority: {exp['priority']}")
        if exp.get("labels"):
            print(f"Labels: {', '.join(exp['labels'])}")
        print()
        if facets:
            print("Facets:")
            for f in facets:
                icon = status_icon(f.get("status", "untested"))
                test = f" (test: {f['test']})" if f.get("test") else ""
                print(f"  {icon} {f['id']} — {f['text']}{test}")
        else:
            print("No facets yet — decompose this expectation into testable facets.")

def cmd_show(args):
    catalog, _ = load_catalog()
    nodes = catalog["nodes"]
    node = get_node(nodes, args.id)
    if not node:
        print(f"Error: Node '{args.id}' not found.", file=sys.stderr)
        sys.exit(1)

    chain = get_ancestor_chain(nodes, args.id)
    children = get_children(nodes, args.id)
    status = compute_status(nodes, node)

    if args.json:
        print(json.dumps({
            "node": node,
            "status": status,
            "children": children,
            "ancestor_chain": chain,
        }))
    else:
        # Show ancestor chain
        if len(chain) > 1:
            print("Context:")
            for i, a in enumerate(chain[:-1]):
                indent = "  " * i
                print(f"  {indent}{a['id']} ({a['type']}) — {a['text']}")
            print()

        print(f"{'Type:':<10} {node['type']}")
        print(f"{'ID:':<10} {node['id']}")
        print(f"{'Text:':<10} {node['text']}")
        print(f"{'Status:':<10} {status}")
        if node.get("parent"):
            print(f"{'Parent:':<10} {node['parent']}")
        if node.get("priority"):
            print(f"{'Priority:':<10} {node['priority']}")
        if node.get("labels"):
            print(f"{'Labels:':<10} {', '.join(node['labels'])}")
        if node.get("test"):
            print(f"{'Test:':<10} {node['test']}")

        if children:
            print(f"\nChildren ({len(children)}):")
            for c in children:
                s = compute_status(nodes, c)
                icon = status_icon(s)
                print(f"  {icon} {c['id']} ({c['type']}) — {c['text']}")

def cmd_tree(args):
    catalog, _ = load_catalog()
    nodes = catalog["nodes"]
    roots = [n for n in nodes if n.get("parent") is None]
    roots.sort(key=lambda n: n.get("priority", 99))

    if args.json:
        def build_tree(node):
            children = get_children(nodes, node["id"])
            children.sort(key=lambda n: n.get("priority", 99))
            return {
                **node,
                "computed_status": compute_status(nodes, node),
                "children": [build_tree(c) for c in children],
            }
        print(json.dumps([build_tree(r) for r in roots], indent=2))
    else:
        def print_tree(node, indent=0):
            status = compute_status(nodes, node)
            icon = status_icon(status)
            prefix = "  " * indent
            type_label = node["type"][0].upper()
            print(f"{prefix}{icon} {node['id']} [{type_label}] {node['text']}")
            children = get_children(nodes, node["id"])
            children.sort(key=lambda n: n.get("priority", 99))
            for c in children:
                print_tree(c, indent + 1)

        if not roots:
            print("Catalog is empty. Use 'bdd add goal \"...\"' to get started.")
        for r in roots:
            print_tree(r)

def cmd_add(args):
    catalog, path = load_catalog()
    nodes = catalog["nodes"]
    ntype = args.type

    if ntype not in TYPE_PREFIX:
        print(f"Error: Type must be one of: goal, expectation, facet", file=sys.stderr)
        sys.exit(1)

    # Validate parent
    parent_id = args.parent
    if parent_id:
        parent = get_node(nodes, parent_id)
        if not parent:
            print(f"Error: Parent '{parent_id}' not found.", file=sys.stderr)
            sys.exit(1)
    elif ntype == "expectation":
        # Expectations must have a goal parent
        goals = [n for n in nodes if n["type"] == "goal"]
        if len(goals) == 1:
            parent_id = goals[0]["id"]
        elif len(goals) > 1:
            print("Error: Multiple goals exist. Use --parent to specify.", file=sys.stderr)
            sys.exit(1)
    elif ntype == "facet":
        # Facets must have an expectation parent
        expectations = [n for n in nodes if n["type"] == "expectation"]
        if len(expectations) == 1:
            parent_id = expectations[0]["id"]
        elif len(expectations) > 1:
            print("Error: Multiple expectations exist. Use --parent to specify.", file=sys.stderr)
            sys.exit(1)

    new_id = next_id(nodes, TYPE_PREFIX[ntype])

    node = {
        "id": new_id,
        "type": ntype,
        "text": args.text,
        "parent": parent_id,
    }

    if ntype in ("goal", "expectation"):
        node["priority"] = args.priority or 1
        node["labels"] = args.label or []
    elif ntype == "facet":
        node["test"] = None
        node["status"] = "untested"

    nodes.append(node)
    save_catalog(catalog, path)

    if args.json:
        print(json.dumps(node))
    else:
        print(f"Added {ntype}: {new_id} — {args.text}")
        if parent_id:
            print(f"  Parent: {parent_id}")

def cmd_mark(args):
    catalog, path = load_catalog()
    nodes = catalog["nodes"]
    node = get_node(nodes, args.facet_id)

    if not node:
        print(f"Error: Node '{args.facet_id}' not found.", file=sys.stderr)
        sys.exit(1)
    if node["type"] != "facet":
        print(f"Error: '{args.facet_id}' is a {node['type']}, not a facet. Only facets can be marked.", file=sys.stderr)
        sys.exit(1)

    valid = ("passing", "failing", "untested")
    if args.status not in valid:
        print(f"Error: Status must be one of: {', '.join(valid)}", file=sys.stderr)
        sys.exit(1)

    old = node.get("status", "untested")
    node["status"] = args.status
    save_catalog(catalog, path)

    if args.json:
        print(json.dumps({"id": node["id"], "old_status": old, "new_status": args.status}))
    else:
        print(f"Marked {args.facet_id}: {old} -> {args.status}")

def cmd_link(args):
    catalog, path = load_catalog()
    nodes = catalog["nodes"]
    node = get_node(nodes, args.facet_id)

    if not node:
        print(f"Error: Node '{args.facet_id}' not found.", file=sys.stderr)
        sys.exit(1)
    if node["type"] != "facet":
        print(f"Error: '{args.facet_id}' is a {node['type']}, not a facet.", file=sys.stderr)
        sys.exit(1)

    node["test"] = args.test_path
    save_catalog(catalog, path)

    if args.json:
        print(json.dumps({"id": node["id"], "test": args.test_path}))
    else:
        print(f"Linked {args.facet_id} -> {args.test_path}")

def cmd_remove(args):
    catalog, path = load_catalog()
    nodes = catalog["nodes"]
    node = get_node(nodes, args.id)

    if not node:
        print(f"Error: Node '{args.id}' not found.", file=sys.stderr)
        sys.exit(1)

    children = get_children(nodes, args.id)
    if children and not args.force:
        child_ids = [c["id"] for c in children]
        print(f"Warning: '{args.id}' has {len(children)} children: {', '.join(child_ids)}", file=sys.stderr)
        print(f"Children will be orphaned (parent set to null). Use --force to confirm.", file=sys.stderr)
        sys.exit(1)

    # Orphan children
    for c in children:
        c["parent"] = None

    catalog["nodes"] = [n for n in nodes if n["id"] != args.id]
    save_catalog(catalog, path)

    if args.json:
        print(json.dumps({"removed": args.id, "orphaned": [c["id"] for c in children]}))
    else:
        print(f"Removed {args.id}")
        if children:
            print(f"  Orphaned: {', '.join(c['id'] for c in children)}")

def cmd_edit(args):
    catalog, path = load_catalog()
    nodes = catalog["nodes"]
    node = get_node(nodes, args.id)

    if not node:
        print(f"Error: Node '{args.id}' not found.", file=sys.stderr)
        sys.exit(1)

    old = node["text"]
    node["text"] = args.text
    save_catalog(catalog, path)

    if args.json:
        print(json.dumps({"id": args.id, "old_text": old, "new_text": args.text}))
    else:
        print(f"Updated {args.id}: {args.text}")

def cmd_related(args):
    """Show motivation chain for a source file (requires coverage map)."""
    coverage_path = os.path.join(os.path.dirname(find_catalog()), "coverage_map.json")
    if not os.path.exists(coverage_path):
        if args.json:
            print(json.dumps({"error": "No coverage_map.json found. Run tests with coverage to generate it."}))
        else:
            print("No coverage_map.json found. Run tests with coverage to generate it.")
        return

    with open(coverage_path) as f:
        coverage = json.load(f)

    catalog, _ = load_catalog()
    nodes = catalog["nodes"]

    filepath = args.filepath
    # Find matching files (substring match on keys)
    matched_files = {f: lines for f, lines in coverage.items() if filepath in f}

    if not matched_files:
        if args.json:
            print(json.dumps({"file": filepath, "related": []}))
        else:
            print(f"No catalog entries related to {filepath}")
        return

    # Collect facet IDs, optionally filtering by line range
    line_range = getattr(args, 'line_range', None)
    line_start = int(line_range[0]) if line_range else None
    line_end = int(line_range[1]) if line_range else None

    results = []
    for src_file, line_map in matched_files.items():
        facet_ids = set()
        for line_num, fids in line_map.items():
            if line_start is not None and line_end is not None:
                if not (line_start <= int(line_num) <= line_end):
                    continue
            for fid in fids:
                facet_ids.add(fid)

        chains = []
        for fid in sorted(facet_ids):
            chain = get_ancestor_chain(nodes, fid)
            if chain:
                chains.append({
                    "facet_id": fid,
                    "chain": [{"id": n["id"], "type": n["type"], "text": n["text"]} for n in chain]
                })
        if facet_ids:
            results.append({"file": src_file, "facet_ids": sorted(facet_ids), "chains": chains})

    if args.json:
        print(json.dumps({"file": filepath, "related": results}))
    else:
        for r in results:
            print(f"{r['file']}:")
            for c in r["chains"]:
                chain_str = " > ".join(f"{n['id']} ({n['type']}): {n['text']}" for n in c["chain"])
                print(f"  {chain_str}")

def cmd_coverage(args):
    """Parse per-test coverage data and update coverage_map.json."""
    import xml.etree.ElementTree as ET

    catalog, cat_path = load_catalog()
    nodes = catalog["nodes"]
    project_root = os.path.dirname(cat_path)
    coverage_map_path = os.path.join(project_root, "coverage_map.json")

    # Build reverse map: test_identifier -> [facet_id]
    test_to_facets = {}
    for n in nodes:
        if n["type"] == "facet" and n.get("test"):
            test_to_facets.setdefault(n["test"], []).append(n["id"])

    # Read coverage input
    if args.dir:
        # lcov-dir mode: directory of per-test LCOV files
        fmt = "lcov-dir"
        raw = None
    elif args.file:
        with open(args.file) as f:
            raw = f.read()
    else:
        raw = sys.stdin.read()

    if not args.dir:
        fmt = args.format
        if not fmt:
            stripped = raw.strip()
            if stripped.startswith("{"):
                fmt = "coverage-json"
            elif stripped.startswith("TN:") or stripped.startswith("SF:"):
                fmt = "lcov"
            elif stripped.startswith("<?xml") or stripped.startswith("<coverage"):
                fmt = "cobertura"
            else:
                print("Error: Could not auto-detect coverage format. Use --format.", file=sys.stderr)
                sys.exit(1)

    # coverage_map: {filepath: {line_num_str: set(facet_ids)}}
    coverage_map = {}

    def add_line(filepath, line_num, facet_ids):
        """Add facet IDs for a specific line of a file."""
        filepath = os.path.relpath(filepath, project_root) if os.path.isabs(filepath) else filepath
        if filepath not in coverage_map:
            coverage_map[filepath] = {}
        line_str = str(line_num)
        if line_str not in coverage_map[filepath]:
            coverage_map[filepath][line_str] = set()
        coverage_map[filepath][line_str].update(facet_ids)

    if fmt == "coverage-json":
        # coverage.py JSON with contexts: {files: {filepath: {contexts: {context_name: [line_nums]}}}}
        # or the newer format: {files: {filepath: {executed_lines: [...], contexts: [...]}}}
        data = json.loads(raw)
        files = data.get("files", {})
        for filepath, file_data in files.items():
            contexts = file_data.get("contexts", {})
            if isinstance(contexts, dict):
                # Format: {context_name: [line_numbers]}
                for context_name, lines in contexts.items():
                    # Match context to test identifier
                    matched_facets = []
                    for test_id, facet_ids in test_to_facets.items():
                        if test_id in context_name or context_name in test_id:
                            matched_facets.extend(facet_ids)
                    if matched_facets:
                        for line in lines:
                            add_line(filepath, line, matched_facets)

    elif fmt == "lcov":
        # Single LCOV file — whole-suite, no per-test info
        # Map all hit lines to all facets that have linked tests
        all_facet_ids = []
        for fids in test_to_facets.values():
            all_facet_ids.extend(fids)
        all_facet_ids = list(set(all_facet_ids))

        current_file = None
        for line in raw.splitlines():
            if line.startswith("SF:"):
                current_file = line[3:].strip()
            elif line.startswith("DA:") and current_file:
                parts = line[3:].split(",")
                if len(parts) >= 2 and int(parts[1]) > 0:
                    add_line(current_file, int(parts[0]), all_facet_ids)
            elif line.startswith("end_of_record"):
                current_file = None

    elif fmt == "lcov-dir":
        # Directory of per-test LCOV files
        # Filename convention: test identifier with / replaced by __ and :: kept
        dir_path = args.dir
        for fname in os.listdir(dir_path):
            if not fname.endswith(".lcov"):
                continue
            # Derive test identifier from filename
            test_id = fname[:-5].replace("__", "/")
            facet_ids = test_to_facets.get(test_id, [])
            if not facet_ids:
                # Try fuzzy match
                for tid, fids in test_to_facets.items():
                    if test_id in tid or tid in test_id:
                        facet_ids.extend(fids)
            if not facet_ids:
                continue

            with open(os.path.join(dir_path, fname)) as f:
                lcov_data = f.read()
            current_file = None
            for line in lcov_data.splitlines():
                if line.startswith("SF:"):
                    current_file = line[3:].strip()
                elif line.startswith("DA:") and current_file:
                    parts = line[3:].split(",")
                    if len(parts) >= 2 and int(parts[1]) > 0:
                        add_line(current_file, int(parts[0]), facet_ids)
                elif line.startswith("end_of_record"):
                    current_file = None

    elif fmt == "cobertura":
        # Cobertura XML — whole-suite
        all_facet_ids = []
        for fids in test_to_facets.values():
            all_facet_ids.extend(fids)
        all_facet_ids = list(set(all_facet_ids))

        root = ET.fromstring(raw)
        for cls in root.iter("class"):
            filename = cls.get("filename", "")
            if not filename:
                continue
            for line_el in cls.iter("line"):
                line_num = line_el.get("number")
                hits = int(line_el.get("hits", "0"))
                if line_num and hits > 0:
                    add_line(filename, int(line_num), all_facet_ids)

    # Convert sets to sorted lists for JSON serialization
    serializable = {}
    for filepath in sorted(coverage_map):
        serializable[filepath] = {}
        for line_num in sorted(coverage_map[filepath], key=lambda x: int(x)):
            serializable[filepath][line_num] = sorted(coverage_map[filepath][line_num])

    with open(coverage_map_path, "w") as f:
        json.dump(serializable, f, indent=2)
        f.write("\n")

    if args.json:
        print(json.dumps({"files_mapped": len(serializable), "path": coverage_map_path}))
    else:
        total_lines = sum(len(lines) for lines in serializable.values())
        print(f"Coverage map updated: {len(serializable)} files, {total_lines} lines mapped")
        print(f"Written to {coverage_map_path}")

SETUP_NODES = [
    {
        "type": "goal",
        "text": "The project is set up for BDD development",
        "priority": 0,
        "labels": ["setup"],
    },
    {
        "type": "expectation",
        "text": "Per-test coverage tooling is installed and working",
        "parent_ref": "setup_goal",
        "priority": 0,
        "labels": ["setup"],
    },
    {
        "type": "facet",
        "text": "The coverage tool for this project's language is installed",
        "parent_ref": "coverage_exp",
    },
    {
        "type": "facet",
        "text": "Running the test command produces a per-test coverage report",
        "parent_ref": "coverage_exp",
    },
    {
        "type": "facet",
        "text": "bdd coverage parses the report and generates coverage_map.json",
        "parent_ref": "coverage_exp",
    },
    {
        "type": "expectation",
        "text": "Project details are documented in .claude/CLAUDE.md",
        "parent_ref": "setup_goal",
        "priority": 0,
        "labels": ["setup"],
    },
    {
        "type": "facet",
        "text": "Stack, build command, and test-with-coverage command are filled in",
        "parent_ref": "docs_exp",
    },
    {
        "type": "facet",
        "text": "Key paths are documented",
        "parent_ref": "docs_exp",
    },
    {
        "type": "expectation",
        "text": "Behavior test infrastructure exists and works",
        "parent_ref": "setup_goal",
        "priority": 0,
        "labels": ["setup"],
    },
    {
        "type": "facet",
        "text": "A tests/ directory exists with at least one behavior test",
        "parent_ref": "tests_exp",
    },
    {
        "type": "facet",
        "text": "The behavior test exercises the full program (not isolated units)",
        "parent_ref": "tests_exp",
    },
    {
        "type": "facet",
        "text": "The behavior test is linked to a catalog facet via bdd link",
        "parent_ref": "tests_exp",
    },
]

SETUP_RULE = """\
# Project Setup Guide

This file is read by the planning agent when working on setup expectations.
It explains how to set up per-test coverage and behavior test infrastructure.

## Step 1: Detect the Project Language

Check for these files to determine the stack:
- `Cargo.toml` → Rust
- `package.json` → Node.js
- `pyproject.toml` / `setup.py` / `requirements.txt` → Python
- `go.mod` → Go

If no project files exist, ask the human what language to use, then create
the initial project structure (e.g., `cargo init`, `npm init`, etc.).

## Step 2: Install Per-Test Coverage Tooling

### Rust
```bash
rustup component add llvm-tools-preview
cargo install cargo-llvm-cov
```
Test command: `cargo llvm-cov --lcov --output-path coverage.lcov && bdd coverage --file coverage.lcov`

Note: For per-test granularity with Rust, run each integration test separately
with `cargo llvm-cov` and merge results using `--lcov-dir` mode.

### Python
```bash
pip install pytest pytest-cov
```
Test command: `pytest tests/ --cov=<source_pkg> --cov-context=test --cov-report=json:coverage.json && bdd coverage --file coverage.json`

The `--cov-context=test` flag is critical — it records which test covered each line.

### Node.js
```bash
npm install --save-dev c8  # or nyc
```
Test command: `NODE_V8_COVERAGE=.coverage npx jest && bdd coverage --dir .coverage`

Or with c8: `npx c8 --reporter=lcov jest && bdd coverage --file coverage/lcov.info`

### Go
```bash
# No additional tooling needed — go test has built-in coverage
```
Test command: `go test -coverprofile=coverage.out ./... && bdd coverage --file coverage.out --format lcov`

## Step 3: Write the First Behavior Test

Behavior tests exercise the FULL program, not isolated units:
- For a CLI tool: invoke the binary with inputs, check stdout/stderr
- For a web app: start the server, make HTTP requests, check responses
- For a game: invoke the entry point, check initial state via introspection
- For a library: import and run the public API end-to-end

Write the test in the project's native test framework (pytest, #[test], jest, etc.).
Link it to a catalog facet with `bdd link <facet-id> <test-identifier>`.

## Step 4: Verify the Coverage Pipeline

Run the full test command and verify:
1. Tests pass
2. A coverage report is produced
3. `bdd coverage --file <report>` creates `coverage_map.json`
4. `bdd related <some-source-file>` returns results with line-level facet mapping

## Step 5: Fill in CLAUDE.md

Edit `.claude/CLAUDE.md` and fill in:
- **Stack**: language, framework, key libraries
- **Build**: the build command
- **Test (with per-test coverage)**: the full test + coverage + bdd coverage pipeline
- **Key Paths**: important source directories and files

## Step 6: Update settings.json Permissions

Edit `.claude/settings.json` to add project-specific Bash permissions:
- Build commands (e.g., `Bash(cargo build*)`)
- Test commands (e.g., `Bash(cargo test*)`, `Bash(cargo llvm-cov*)`)
- Coverage commands (`Bash(bdd coverage*)`)
"""

def cmd_setup(args):
    """Set up BDD framework in a project directory."""
    import shutil

    project_dir = os.path.abspath(args.project_dir or os.getcwd())
    bdd_dir = os.path.dirname(os.path.realpath(__file__))
    framework_src = os.path.join(bdd_dir, "framework")
    claude_dst = os.path.join(project_dir, ".claude")
    catalog_path = os.path.join(project_dir, CATALOG_FILE)

    if not os.path.isdir(framework_src):
        print(f"Error: Framework directory not found at {framework_src}", file=sys.stderr)
        sys.exit(1)

    # Step 1: Copy framework to .claude/
    if os.path.isdir(claude_dst):
        if not args.force:
            print(f".claude/ already exists in {project_dir}. Use --force to overwrite.", file=sys.stderr)
            sys.exit(1)
        shutil.rmtree(claude_dst)
    shutil.copytree(framework_src, claude_dst)
    print(f"Copied framework to {claude_dst}")

    # Step 2: Create or update catalog.json with setup expectations
    if os.path.exists(catalog_path):
        with open(catalog_path) as f:
            catalog = json.load(f)
        print(f"Found existing {CATALOG_FILE} ({len(catalog['nodes'])} nodes)")
    else:
        catalog = {"version": 1, "nodes": []}
        print(f"Created new {CATALOG_FILE}")

    nodes = catalog["nodes"]

    # Check if setup goal already exists
    existing_setup = [n for n in nodes if n.get("labels") and "setup" in n["labels"] and n["type"] == "goal"]
    if existing_setup:
        print(f"Setup goal already exists ({existing_setup[0]['id']}). Skipping catalog seeding.")
    else:
        # Inject setup nodes with proper IDs and parent references
        ref_map = {}  # ref_name -> actual_id

        for template in SETUP_NODES:
            ntype = template["type"]
            new_id = next_id(nodes, TYPE_PREFIX[ntype])

            node = {
                "id": new_id,
                "type": ntype,
                "text": template["text"],
            }

            # Resolve parent
            parent_ref = template.get("parent_ref")
            if parent_ref:
                node["parent"] = ref_map.get(parent_ref)
            else:
                node["parent"] = None

            if ntype in ("goal", "expectation"):
                node["priority"] = template.get("priority", 1)
                node["labels"] = template.get("labels", [])
            elif ntype == "facet":
                node["test"] = None
                node["status"] = "untested"

            nodes.append(node)

            # Store refs for child lookups
            if ntype == "goal" and "setup" in template.get("labels", []):
                ref_map["setup_goal"] = new_id
            elif ntype == "expectation" and "coverage" in template["text"].lower():
                ref_map["coverage_exp"] = new_id
            elif ntype == "expectation" and "documented" in template["text"].lower():
                ref_map["docs_exp"] = new_id
            elif ntype == "expectation" and "infrastructure" in template["text"].lower():
                ref_map["tests_exp"] = new_id

        save_catalog(catalog, catalog_path)
        setup_goal_id = ref_map.get("setup_goal", "?")
        print(f"Seeded setup expectations (goal: {setup_goal_id})")

    # Step 3: Create setup.md rule
    setup_rule_path = os.path.join(claude_dst, "rules", "setup.md")
    os.makedirs(os.path.dirname(setup_rule_path), exist_ok=True)
    with open(setup_rule_path, "w") as f:
        f.write(SETUP_RULE)
    print(f"Created {setup_rule_path}")

    # Summary
    print()
    print("Setup complete. Next steps:")
    print("  1. cd to your project directory")
    print("  2. Run the agent loop: ./loop.sh")
    print("     Or interactively: claude")
    print("  3. The agent will pick up setup expectations first (priority 0)")
    print()
    if os.path.exists(catalog_path):
        # Show status
        with open(catalog_path) as f:
            cat = json.load(f)
        n = cat["nodes"]
        goals = len([x for x in n if x["type"] == "goal"])
        exps = len([x for x in n if x["type"] == "expectation"])
        facets = len([x for x in n if x["type"] == "facet"])
        print(f"Catalog: {goals} goals, {exps} expectations, {facets} facets")

def main():
    parser = argparse.ArgumentParser(prog="bdd", description="BDD Catalog Manager")
    parser.add_argument("--json", action="store_true", help="Output as JSON")
    sub = parser.add_subparsers(dest="command")

    # init
    p = sub.add_parser("init", help="Create empty catalog.json")
    p.add_argument("--force", action="store_true", help="Overwrite existing catalog")

    # status
    sub.add_parser("status", help="Summary of catalog")

    # next
    sub.add_parser("next", help="Next unsatisfied expectation to work on")

    # show
    p = sub.add_parser("show", help="Show details of a node")
    p.add_argument("id", help="Node ID (e.g. g-001, e-001, f-001)")

    # tree
    sub.add_parser("tree", help="Hierarchical view of catalog")

    # related
    p = sub.add_parser("related", help="Motivation chain for a source file")
    p.add_argument("filepath", help="Source file path")
    p.add_argument("--lines", nargs=2, metavar=("START", "END"), dest="line_range",
                   help="Filter to lines in range START..END")

    # add
    p = sub.add_parser("add", help="Add a node to the catalog")
    p.add_argument("type", choices=["goal", "expectation", "facet"], help="Node type")
    p.add_argument("text", help="Node text")
    p.add_argument("--parent", help="Parent node ID")
    p.add_argument("--priority", type=int, help="Priority (lower = higher)")
    p.add_argument("--label", action="append", help="Label (repeatable)")

    # mark
    p = sub.add_parser("mark", help="Update facet status")
    p.add_argument("facet_id", help="Facet ID")
    p.add_argument("status", choices=["passing", "failing", "untested"], help="New status")

    # link
    p = sub.add_parser("link", help="Link facet to test file")
    p.add_argument("facet_id", help="Facet ID")
    p.add_argument("test_path", help="Path to test file")

    # remove
    p = sub.add_parser("remove", help="Remove a node")
    p.add_argument("id", help="Node ID")
    p.add_argument("--force", action="store_true", help="Confirm removal of node with children")

    # edit
    p = sub.add_parser("edit", help="Edit node text")
    p.add_argument("id", help="Node ID")
    p.add_argument("text", help="New text")

    # setup
    p = sub.add_parser("setup", help="Set up BDD framework in a project")
    p.add_argument("project_dir", nargs="?", help="Project directory (default: current)")
    p.add_argument("--force", action="store_true", help="Overwrite existing .claude/ directory")

    # coverage
    p = sub.add_parser("coverage", help="Parse coverage data and update coverage_map.json")
    p.add_argument("--file", help="Coverage report file (default: read stdin)")
    p.add_argument("--dir", help="Directory of per-test LCOV files (lcov-dir format)")
    p.add_argument("--format", choices=["coverage-json", "lcov", "lcov-dir", "cobertura"],
                   help="Coverage format (auto-detected if not specified)")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(1)

    # Dispatch
    cmd = {
        "init": cmd_init,
        "status": cmd_status,
        "next": cmd_next,
        "show": cmd_show,
        "tree": cmd_tree,
        "related": cmd_related,
        "add": cmd_add,
        "mark": cmd_mark,
        "link": cmd_link,
        "remove": cmd_remove,
        "edit": cmd_edit,
        "coverage": cmd_coverage,
        "setup": cmd_setup,
    }
    cmd[args.command](args)

if __name__ == "__main__":
    main()
